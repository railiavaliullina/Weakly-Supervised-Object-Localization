{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    # parameters for dataset and dataloader\n",
    "    'data':\n",
    "        {\n",
    "            'dataset':\n",
    "                {\n",
    "                    'root_path': '/kaggle/input/coco-2017-dataset/coco2017',  # '/datasets/homeworks/cv segmentation/',\n",
    "                    'nb_train_images': 562331,\n",
    "                    'nb_val_images': 36334,\n",
    "                    'nb_classes': 80\n",
    "                },\n",
    "            'dataloader':\n",
    "                {\n",
    "                    'batch_size': 16\n",
    "                }\n",
    "\n",
    "\n",
    "        },\n",
    "\n",
    "    # parameters for setting up training parameters\n",
    "    'train':\n",
    "        {\n",
    "            'optimizer':\n",
    "                {\n",
    "                    'lr': 1e-3,\n",
    "                    'weight_decay': 1e-4\n",
    "                },\n",
    "            'epochs': 100\n",
    "\n",
    "        },\n",
    "\n",
    "    # parameters for model evaluation\n",
    "    \"eval\":\n",
    "        {\n",
    "            'evaluate_on_train_data': False,\n",
    "            'evaluate_before_training': False,\n",
    "        },\n",
    "\n",
    "    # parameters for logging training process, saving/restoring model\n",
    "    \"logging\":\n",
    "        {\n",
    "            'log_metrics': True,\n",
    "            'experiment_name': 'coco_classification',\n",
    "            'checkpoints_dir': 'checkpoints/',\n",
    "            'save_model': True,\n",
    "            'load_model': False,\n",
    "            'epoch_to_load': 20,\n",
    "            'save_frequency': 1,\n",
    "        },\n",
    "\n",
    "    # parameters to debug training and check if everything is ok\n",
    "    \"debug\":\n",
    "        {\n",
    "            # to check batches before training\n",
    "            \"save_batch\":\n",
    "                {\n",
    "                    \"enable\": False,\n",
    "                    \"nrof_batches_to_save\": 5,\n",
    "                    \"path_to_save\": 'batches_images/',\n",
    "                },\n",
    "            \"overfit_on_batch\":\n",
    "                {\n",
    "                    \"enable\": False,\n",
    "                    \"nb_iters\": 1000,\n",
    "                }\n",
    "        },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\" data/coco_80_dataset.py \"\"\"\n",
    "\n",
    "from torch.utils import data\n",
    "from PIL import Image\n",
    "from pycocotools.coco import COCO\n",
    "from torchvision import transforms\n",
    "from pprint import pprint\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "\n",
    "\n",
    "class CocoClsDataset(data.Dataset):\n",
    "    def __init__(self, root_dir, ann_file, img_dir, phase, less_sample=False):\n",
    "        self.ann_file = os.path.join(root_dir, ann_file)\n",
    "        self.img_dir = os.path.join(root_dir, img_dir)\n",
    "        self.coco = COCO(self.ann_file)\n",
    "        self.dataset_type = phase\n",
    "\n",
    "        if phase == 'train':\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.Resize((224, 224)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "            ])\n",
    "        else:\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.Resize((224, 224)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "            ])\n",
    "\n",
    "        cat_ids = self.coco.getCatIds()\n",
    "        categories = self.coco.dataset['categories']\n",
    "        self.id2cat = dict()\n",
    "        for category in categories:\n",
    "            self.id2cat[category['id']] = category['name']\n",
    "        self.id2label = {category['id']: label for label, category in enumerate(categories)}\n",
    "        self.label2id = {v: k for k, v in self.id2label.items()}\n",
    "\n",
    "        tmp_ann_ids = self.coco.getAnnIds()\n",
    "        self.ann_ids = []\n",
    "        for ann_id in tmp_ann_ids:\n",
    "            ann = self.coco.loadAnns([ann_id])[0]\n",
    "            x, y, w, h = ann['bbox']\n",
    "            x, y, w, h = int(x), int(y), int(w), int(h)\n",
    "            if ann['area'] <= 0 or w < 1 or h < 1 or ann['iscrowd']:\n",
    "                continue\n",
    "            self.ann_ids.append(ann_id)\n",
    "\n",
    "        self._cal_num_dict()\n",
    "\n",
    "        if phase == 'train' and less_sample:\n",
    "            self.ann_ids = self._mining_sample()\n",
    "\n",
    "        print('total_length of dataset:', len(self))\n",
    "\n",
    "    def _cal_num_dict(self):\n",
    "        self.num_dict = {}\n",
    "        for ann_id in self.ann_ids:\n",
    "            ann = self.coco.loadAnns([ann_id])[0]\n",
    "            cat = self.id2cat[ann['category_id']]\n",
    "            num = self.num_dict.get(cat, 0)\n",
    "            self.num_dict[cat] = num + 1\n",
    "\n",
    "    def _mining_sample(self):\n",
    "        self.num_dict = {}\n",
    "        tmp_ann_ids = []\n",
    "        for ann_id in self.ann_ids:\n",
    "            ann = self.coco.loadAnns([ann_id])[0]\n",
    "            cat = self.id2cat[ann['category_id']]\n",
    "            num = self.num_dict.get(cat, 0)\n",
    "            if num >= 20000:\n",
    "                continue\n",
    "            self.num_dict[cat] = num + 1\n",
    "            tmp_ann_ids.append(ann_id)\n",
    "        return tmp_ann_ids\n",
    "\n",
    "    def _load_bg_anns(self):\n",
    "        assert os.path.exists(self.bg_bboxes_file)\n",
    "        bg_anns = []\n",
    "        with open(self.bg_bboxes_file, 'r') as f:\n",
    "            line = f.readline()\n",
    "            while line:\n",
    "                if line.strip() == '':\n",
    "                    break\n",
    "                file_name, num = line.strip().split()\n",
    "                for _ in range(int(num)):\n",
    "                    bbox = f.readline()\n",
    "                    bbox = bbox.strip().split()\n",
    "                    bbox = [float(i) for i in bbox]\n",
    "                    w = bbox[2] - bbox[0] + 1\n",
    "                    h = bbox[3] - bbox[1] + 1\n",
    "                    bbox[2], bbox[3] = w, h\n",
    "                    ann = dict(\n",
    "                        file_name=file_name,\n",
    "                        bbox=bbox)\n",
    "                    bg_anns.append(ann)\n",
    "                line = f.readline()\n",
    "        return bg_anns\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ann_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        ann = self.coco.loadAnns([self.ann_ids[idx]])[0]\n",
    "\n",
    "        cat_id = ann['category_id']\n",
    "        label = self.id2label[cat_id]\n",
    "\n",
    "        img_meta = self.coco.loadImgs(ann['image_id'])[0]\n",
    "        img_path = os.path.join(self.img_dir, img_meta['file_name'])\n",
    "\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        x, y, w, h = ann['bbox']\n",
    "        x, y, w, h = int(x), int(y), int(w), int(h)\n",
    "        img = img.crop((x, y, x + w - 1, y + h - 1))\n",
    "\n",
    "        # save_img = img.resize((224, 224), Image.BILINEAR)\n",
    "        # save_img.save('test.jpg')\n",
    "\n",
    "        try:\n",
    "            img = self.transform(img)\n",
    "        except:\n",
    "            print(img.mode)\n",
    "            exit(0)\n",
    "        return img, label\n",
    "\n",
    "\n",
    "def get_data(cfg):\n",
    "    \"\"\"\n",
    "    Gets data and returns train, test dataloaders\n",
    "    :param cfg: cfg['data'] part of config\n",
    "    :return: train, test dataloaders\n",
    "    \"\"\"\n",
    "    print(f'Getting train set...')\n",
    "    train_set = CocoClsDataset(root_dir=cfg['dataset']['root_path'],\n",
    "                               ann_file='annotations/instances_train2017.json',\n",
    "                               img_dir='train2017',\n",
    "                               phase='train',\n",
    "                               less_sample=True)\n",
    "    print('length: ', len(train_set))\n",
    "    pprint(train_set.num_dict)\n",
    "    train_dl = DataLoader(train_set, batch_size=cfg['dataloader']['batch_size'], shuffle=True)\n",
    "\n",
    "    print(f'Getting test set...')\n",
    "    test_set = CocoClsDataset(root_dir=cfg['dataset']['root_path'],\n",
    "                              ann_file='annotations/instances_val2017.json',\n",
    "                              img_dir='val2017',\n",
    "                              phase='val',\n",
    "                              less_sample=True)\n",
    "    print('length: ', len(test_set))\n",
    "    pprint(test_set.num_dict)\n",
    "    test_dl = DataLoader(test_set, batch_size=cfg['dataloader']['batch_size'])\n",
    "\n",
    "    return train_dl, test_dl\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\" models/resnet50.py \"\"\"\n",
    "\n",
    "import torchvision\n",
    "import torch\n",
    "\n",
    "\n",
    "def get_model(cfg):\n",
    "    \"\"\"\n",
    "    :param cfg: config\n",
    "    :return: pretrained on ImageNet resnet-50 model\n",
    "    \"\"\"\n",
    "    print(f'Getting model...')\n",
    "    resnet50 = torchvision.models.resnet50(pretrained=True)\n",
    "    resnet50.features = torch.nn.Sequential(resnet50.conv1, resnet50.bn1, resnet50.relu, resnet50.maxpool,\n",
    "                                            resnet50.layer1,\n",
    "                                            resnet50.layer2, resnet50.layer3, resnet50.layer4)\n",
    "    resnet50.sz_features_output = 2048\n",
    "    resnet50.features_pooling = torch.nn.AvgPool2d(7, stride=1, padding=0, ceil_mode=True, count_include_pad=True)\n",
    "    resnet50.fc = torch.nn.Linear(resnet50.sz_features_output, cfg['data']['dataset']['nb_classes'])\n",
    "\n",
    "    def forward(x):\n",
    "        x = resnet50.features(x)\n",
    "        x = resnet50.features_pooling(x)\n",
    "        bs = x.size(0)\n",
    "        x = x.view(bs, -1)\n",
    "        x = resnet50.fc(x)\n",
    "        return x\n",
    "\n",
    "    resnet50.forward = forward\n",
    "    return resnet50"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\" utils/debug_utils.py \"\"\"\n",
    "\n",
    "import torchvision\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def overfit_on_batch(cfg_overfit_on_batch, cfg_train, train_dl, model, optimizer, criterion):\n",
    "    \"\"\"\n",
    "    Overfits on one batch\n",
    "    :param cfg_overfit_on_batch: cfg['debug']['overfit_on_batch'] part of config\n",
    "    :param train_dl: train dataloader\n",
    "    :param model: resnet50 model\n",
    "    :param optimizer: optimizer\n",
    "    :param criterion: criterion\n",
    "    \"\"\"\n",
    "    train_dl = iter(train_dl)\n",
    "    images, labels = next(train_dl)\n",
    "    model = model.cuda()\n",
    "    accuracies = []\n",
    "\n",
    "    for iter_ in range(cfg_overfit_on_batch['nb_iters']):\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(images.cuda()).cpu()\n",
    "        loss = criterion(logits, labels)\n",
    "        _, predicted = torch.max(logits.data, 1)\n",
    "        accuracy = torch.sum(predicted == labels).item() / labels.size(0) * 100\n",
    "        print(f'iter: {iter_}, acc: {accuracy}, loss: {loss.item()}')\n",
    "\n",
    "        accuracies.append(accuracy)\n",
    "        if len(accuracies) >= 5 and np.min(accuracies[-5:]) == 100:\n",
    "            break\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Overfitting on batch is finished.')\n",
    "\n",
    "\n",
    "def save_batch_images(cfg, train_dl, valid_dl):\n",
    "    \"\"\"\n",
    "    Saves several batches of images as .png file\n",
    "    :param cfg: cfg['debug']['save_batch'] part of config\n",
    "    :param train_dl: train dataloader to saves batches from\n",
    "    :param valid_dl: valid dataloader to saves batches from\n",
    "    \"\"\"\n",
    "    for dl in [train_dl, valid_dl]:\n",
    "        dataset_type = dl.dataset.dataset_type\n",
    "        print(dataset_type)\n",
    "        dl = iter(dl)\n",
    "        for i in range(cfg['nrof_batches_to_save']):\n",
    "            images, labels = next(dl)\n",
    "            print(f'batch {i} labels: {labels}')\n",
    "            torchvision.utils.save_image(images, cfg['path_to_save'] + f'{dataset_type}_batch_{i}.png')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\" utils/eval_utils.py \"\"\"\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# from utils.log_utils import log_metrics\n",
    "\n",
    "\n",
    "def evaluate(cfg_train, cfg_logging, model, dl, epoch, dataset_type, criterion):\n",
    "    \"\"\"\n",
    "    Evaluates on train/valid data\n",
    "    :param cfg_eval: cfg['train'] part of config\n",
    "    :param cfg_logging: cfg['logging'] part of config\n",
    "    :param model: resnet-50 model\n",
    "    :param dl: train/valid dataloader\n",
    "    :param epoch: epoch for logging\n",
    "    :param dataset_type: type of current data ('train' or 'valid')\n",
    "    \"\"\"\n",
    "    print(f'Evaluating on {dataset_type} data...')\n",
    "    eval_start_time = time.time()\n",
    "    correct, total = 0, 0\n",
    "    losses = []\n",
    "    model = model.cuda()\n",
    "\n",
    "    dl_len = len(dl)\n",
    "    for i, (images, labels) in enumerate(dl):\n",
    "        images, labels = images.cuda(), labels.cuda()\n",
    "\n",
    "        if i % 50 == 0:\n",
    "            print(f'iter: {i}/{dl_len}')\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = model(images)\n",
    "        _, predicted = torch.max(logits.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += torch.sum(predicted == labels)\n",
    "\n",
    "\n",
    "        # calculate losses\n",
    "        loss = criterion(logits, labels)\n",
    "        losses.append((loss).item())\n",
    "\n",
    "    log_metrics([f'{dataset_type}_eval/total_loss'], [np.mean(losses)], epoch, cfg_logging)\n",
    "\n",
    "    accuracy = 100 * correct.item() / total\n",
    "    print(f'Accuracy on {dataset_type} data: {accuracy}')\n",
    "\n",
    "    log_metrics([f'{dataset_type}_eval/accuracy'], [accuracy], epoch, cfg_logging)\n",
    "    print(f'Evaluating time: {round((time.time() - eval_start_time) / 60, 3)} min')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\" utils/log_utils.py \"\"\"\n",
    "\n",
    "\n",
    "import mlflow\n",
    "\n",
    "\n",
    "def start_logging(cfg, experiment_name=None):\n",
    "    \"\"\"\n",
    "    Starts mlflow logging\n",
    "    :param cfg: cfg['logging'] part of config\n",
    "    :param experiment_name: experiment name for mlflow visualization\n",
    "    \"\"\"\n",
    "    if cfg['log_metrics']:\n",
    "        experiment_name = cfg['train']['experiment_name'] if experiment_name is None else experiment_name\n",
    "        mlflow.start_run(run_name=experiment_name)\n",
    "\n",
    "\n",
    "def end_logging(cfg):\n",
    "    \"\"\"\n",
    "    Finishes mlflow logging\n",
    "    :param cfg: cfg['logging'] part of config\n",
    "    \"\"\"\n",
    "    if cfg['log_metrics']:\n",
    "        mlflow.end_run()\n",
    "\n",
    "\n",
    "def log_metrics(names, metrics, step, cfg):\n",
    "    \"\"\"\n",
    "    Logs metrics in given list with corresponding names\n",
    "    :param names: list of names of given metrics\n",
    "    :param metrics: list of given metrics\n",
    "    :param step: step to log\n",
    "    :param cfg: cfg['logging'] part of config\n",
    "    \"\"\"\n",
    "    if cfg['log_metrics']:\n",
    "        for name, metric in zip(names, metrics):\n",
    "            mlflow.log_metric(name, metric, step)\n",
    "\n",
    "\n",
    "def log_params(cfg):\n",
    "    \"\"\"\n",
    "    Logs experiment config with all parameters\n",
    "    :param cfg: cfg['logging'] part of config\n",
    "    \"\"\"\n",
    "    if cfg['log_metrics']:\n",
    "        mlflow.log_param('cfg', cfg)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\" utils/train_utils.py \"\"\"\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "def get_optimizer(cfg, model):\n",
    "    \"\"\"\n",
    "    Gets Adam optimizer\n",
    "    :param cfg: cfg['train']['optimizer'] part of config\n",
    "    :param model: resnet-50 model\n",
    "    :return: optimizer\n",
    "    \"\"\"\n",
    "    print(f'Getting optimizer...')\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=cfg['lr'], weight_decay=cfg['weight_decay'])\n",
    "    return opt\n",
    "\n",
    "\n",
    "def get_criterion():\n",
    "    \"\"\"\n",
    "    Gets loss function\n",
    "    :return: loss function\n",
    "    \"\"\"\n",
    "    print(f'Getting criterion...')\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    return criterion\n",
    "\n",
    "\n",
    "def make_training_step(cfg_train, batch, model, criterion, optimizer):\n",
    "    \"\"\"\n",
    "    Makes single parameters updating step.\n",
    "    :param cfg_train: cfg['train'] part of config\n",
    "    :param batch: current batch\n",
    "    :param model: resnet50 model\n",
    "    :param criterion: criterion\n",
    "    :param optimizer: optimizer\n",
    "    :param iter_: current iteration\n",
    "    :return: current loss value\n",
    "    \"\"\"\n",
    "    images, labels = batch\n",
    "    images, labels, model = images.cuda(), labels.cuda(), model.cuda()\n",
    "    optimizer.zero_grad()\n",
    "    logits = model(images)\n",
    "    loss = criterion(logits, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\" trainer/main.py \"\"\"\n",
    "\n",
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# from models.resnet50 import get_model\n",
    "# from data.coco_80_dataset import get_data\n",
    "# from utils.train_utils import get_optimizer, get_criterion, make_training_step\n",
    "# from utils.eval_utils import evaluate\n",
    "# from utils.debug_utils import save_batch_images, overfit_on_batch\n",
    "# from utils.log_utils import start_logging, end_logging, log_metrics, log_params\n",
    "# from configs.config import cfg\n",
    "\n",
    "\n",
    "def train(cfg, train_dl, test_dl, model, optimizer, criterion):\n",
    "    # check data before training\n",
    "    if cfg['debug']['save_batch']['enable']:\n",
    "        save_batch_images(cfg['debug']['save_batch'], train_dl, test_dl)\n",
    "\n",
    "    # check training procedure before training\n",
    "    if cfg['debug']['overfit_on_batch']['enable']:\n",
    "        overfit_on_batch(cfg['debug']['overfit_on_batch'], cfg['train'], train_dl, model, optimizer, criterion)\n",
    "\n",
    "    # save experiment name and experiment params to mlflow\n",
    "    start_logging(cfg['logging'], experiment_name='baseline')\n",
    "    log_params(cfg['logging'])\n",
    "\n",
    "    global_step, start_epoch = 0, 0\n",
    "    if cfg['logging']['load_model']:\n",
    "        print(f'Trying to load checkpoint from epoch {cfg[\"logging\"][\"epoch_to_load\"]}...')\n",
    "        checkpoint = torch.load(cfg['logging']['checkpoints_dir'] + f'checkpoint_{cfg[\"logging\"][\"epoch_to_load\"]}.pth')\n",
    "        load_state_dict = checkpoint['model']\n",
    "        model.load_state_dict(load_state_dict)\n",
    "        start_epoch = checkpoint['epoch'] + 1\n",
    "        global_step = checkpoint['global_step'] + 1\n",
    "        print(f'Successfully loaded checkpoint from epoch {cfg[\"logging\"][\"epoch_to_load\"]}.')\n",
    "\n",
    "    # evaluate on train and test data before training\n",
    "    if cfg['eval']['evaluate_before_training']:\n",
    "        model.eval()\n",
    "        if cfg['eval']['evaluate_on_train_data']:\n",
    "            evaluate(cfg['train'], cfg['logging'], model, train_dl, -1, 'train', criterion)\n",
    "        evaluate(cfg['train'], cfg['logging'], model, test_dl, -1, 'valid', criterion)\n",
    "        model.train()\n",
    "\n",
    "    nb_iters_per_epoch = len(train_dl.dataset) // train_dl.batch_size\n",
    "\n",
    "    # training loop\n",
    "    for epoch in range(start_epoch, cfg['train']['epochs']):\n",
    "        losses = []\n",
    "        epoch_start_time = time.time()\n",
    "        print(f'Epoch: {epoch}')\n",
    "        for iter_, batch in enumerate(train_dl):\n",
    "            loss = make_training_step(cfg['train'], batch, model, criterion, optimizer)\n",
    "            losses.append(loss)\n",
    "            global_step += 1\n",
    "\n",
    "            log_metrics(['train/loss'], [loss], global_step, cfg['logging'])\n",
    "\n",
    "            if global_step % 100 == 0:\n",
    "                mean_loss = np.mean(losses[:-20]) if len(losses) > 20 else np.mean(losses)\n",
    "                print(f'step: {global_step}, total_loss: {mean_loss}')\n",
    "\n",
    "        # log mean loss per epoch\n",
    "        log_metrics(['train/mean_loss'], [np.mean(losses[:-nb_iters_per_epoch])], epoch, cfg['logging'])\n",
    "        print(f'Epoch time: {round((time.time() - epoch_start_time) / 60, 3)} min')\n",
    "\n",
    "        # save model\n",
    "        if cfg['logging']['save_model'] and epoch % cfg['logging']['save_frequency'] == 0:\n",
    "            print('Saving current model...')\n",
    "            state = {\n",
    "                'model': model.state_dict(),\n",
    "                'epoch': epoch,\n",
    "                'global_step': global_step,\n",
    "                'opt': optimizer.state_dict(),\n",
    "            }\n",
    "            torch.save(state, cfg['logging']['checkpoints_dir'] + f'checkpoint_{epoch}.pth')\n",
    "\n",
    "        # evaluate on train and test data\n",
    "        model.eval()\n",
    "        if cfg['eval']['evaluate_on_train_data']:\n",
    "            evaluate(cfg['train'], cfg['logging'], model, train_dl, epoch, 'train', criterion)\n",
    "        evaluate(cfg['train'], cfg['logging'], model, test_dl, epoch, 'valid', criterion)\n",
    "        model.train()\n",
    "\n",
    "    end_logging(cfg['logging'])\n",
    "\n",
    "\n",
    "def run(cfg):\n",
    "    train_dl, test_dl = get_data(cfg['data'])\n",
    "    model = get_model(cfg)\n",
    "    optimizer = get_optimizer(cfg['train']['optimizer'], model)\n",
    "    criterion = get_criterion()\n",
    "\n",
    "    train(cfg, train_dl, test_dl, model, optimizer, criterion)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    start_time = time.time()\n",
    "    run(cfg)\n",
    "    print(f'Total time: {round((time.time() - start_time) / 60, 3)} min')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}